{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4d302c",
   "metadata": {},
   "source": [
    "# Zoom data reduction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is an example of how ESSsans can be used to reduce data from [Zoom at ISIS](https://www.isis.stfc.ac.uk/Pages/Zoom.aspx).\n",
    "The following description is kept relatively brief, for more context see the rest of the documentation.\n",
    "In particular the [Sans2d](./sans2d.ipynb) notebook may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2278d",
   "metadata": {},
   "source": [
    "There are a few things that are not yet handled:\n",
    "\n",
    "- TOF or wavelength masks\n",
    "- Position corrections from user file (not automatically, have manual sample and detector bank offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09234b87",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319162e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import sciline\n",
    "from ess import sans\n",
    "from ess import isissans as isis\n",
    "from ess.sans.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64783c51",
   "metadata": {},
   "source": [
    "### Setup input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    DirectBeamFilename: 'Direct_Zoom_4m_8mm_100522.txt',\n",
    "    isis.CalibrationFilename: '192tubeCalibration_11-02-2019_r5_10lines.nxs',\n",
    "    Filename[SampleRun]: 'ZOOM00034786.nxs',\n",
    "    Filename[EmptyBeamRun]: 'ZOOM00034787.nxs',\n",
    "    isis.SampleOffset: sc.vector([0.0, 0.0, 0.11], unit='m'),\n",
    "    isis.DetectorBankOffset: sc.vector([0.0, 0.0, 0.5], unit='m'),\n",
    "}\n",
    "masks = [\n",
    "    'andru_test.xml',\n",
    "    'left_beg_18_2.xml',\n",
    "    'right_beg_18_2.xml',\n",
    "    'small_bs_232.xml',\n",
    "    'small_BS_31032023.xml',\n",
    "    'tube_1120_bottom.xml',\n",
    "    'tubes_beg_18_2.xml',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a4e01",
   "metadata": {},
   "source": [
    "### Setup reduction parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f11eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[NeXusMonitorName[Incident]] = 'monitor3'\n",
    "params[NeXusMonitorName[Transmission]] = 'monitor5'\n",
    "\n",
    "params[WavelengthBins] = sc.geomspace(\n",
    "    'wavelength', start=1.75, stop=16.5, num=141, unit='angstrom'\n",
    ")\n",
    "\n",
    "params[QBins] = sc.geomspace(dim='Q', start=0.004, stop=0.8, num=141, unit='1/angstrom')\n",
    "\n",
    "params[NonBackgroundWavelengthRange] = sc.array(\n",
    "    dims=['wavelength'], values=[0.7, 17.1], unit='angstrom'\n",
    ")\n",
    "params[CorrectForGravity] = True\n",
    "params[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.upper_bound\n",
    "params[ReturnEvents] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47024f",
   "metadata": {},
   "source": [
    "### Setup reduction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcaec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = sans.providers + isis.providers + (isis.io.read_xml_detector_masking,)\n",
    "providers = providers + (\n",
    "    isis.data.transmission_from_background_run,\n",
    "    isis.data.transmission_from_sample_run,\n",
    "    sans.beam_center_from_center_of_mass,\n",
    ")\n",
    "pipeline = sciline.Pipeline(providers, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951aec10",
   "metadata": {},
   "source": [
    "If Mantid is available, we can use it to load data files.\n",
    "**You must configure the** `DataFolder` **below to point to the directory containing the data files.**\n",
    "Otherwise, we fall back to load intermediate data files that have been prepared for the concrete example in this notebook.\n",
    "If you want to use the workflow with different files you must have Mantid installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66237b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from mantid import ConfigService\n",
    "    import ess.isissans.mantidio\n",
    "\n",
    "    cfg = ConfigService.Instance()\n",
    "    cfg.setLogLevel(3)  # Silence verbose load via Mantid\n",
    "\n",
    "    pipeline[DataFolder] = 'zoom_data'\n",
    "    for provider in isis.mantidio.providers:\n",
    "        pipeline.insert(provider)\n",
    "except ImportError:\n",
    "    import ess.isissans.io\n",
    "\n",
    "    for provider in isis.data.providers:\n",
    "        pipeline.insert(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f942232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cyclebane as cb\n",
    "\n",
    "\n",
    "def merge(*dicts: dict) -> dict:\n",
    "    return {k: v for d in dicts for k, v in d.items()}\n",
    "\n",
    "\n",
    "def make_workflow(\n",
    "    pipeline: sciline.Pipeline, masks: list[str]\n",
    ") -> sciline.task_graph.TaskGraph:\n",
    "    graph = pipeline.get(\n",
    "        IofQ[SampleRun], handler=sciline.HandleAsComputeTimeException()\n",
    "    )\n",
    "    cbgraph = cb.Graph(graph.to_networkx())\n",
    "    cbgraph[MaskedDetectorIDs] = (\n",
    "        cbgraph[MaskedDetectorIDs]\n",
    "        .map({PixelMaskFilename: masks})\n",
    "        .reduce(attrs={\"reduce\": merge})\n",
    "    )\n",
    "    return sciline.task_graph.TaskGraph.from_networkx(cbgraph.to_networkx())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ffc1e",
   "metadata": {},
   "source": [
    "## Reduction\n",
    "\n",
    "### The reduction workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e7c10-3428-4c10-8a5d-fa49b807a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "iofq = make_workflow(pipeline, masks)\n",
    "iofq.visualize(graph_attr={'rankdir': 'LR'}, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77687728",
   "metadata": {},
   "source": [
    "### Running the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558327ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = iofq.compute()\n",
    "da.plot(norm='log', scale={'Q': 'log'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7526fc",
   "metadata": {},
   "source": [
    "### Inspecting intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb922379",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = (\n",
    "    WavelengthMonitor[SampleRun, Incident],\n",
    "    WavelengthMonitor[TransmissionRun[SampleRun], Transmission],\n",
    ")\n",
    "parts = (CleanSummedQ[SampleRun, Numerator], CleanSummedQ[SampleRun, Denominator])\n",
    "iofqs = (IofQ[SampleRun],)\n",
    "keys = monitors + (MaskedData[SampleRun],) + parts + iofqs\n",
    "\n",
    "results = iofq.compute(keys)\n",
    "\n",
    "display(sc.plot({str(key): results[key] for key in monitors}, norm='log'))\n",
    "\n",
    "display(\n",
    "    isis.plot_flat_detector_xy(\n",
    "        results[MaskedData[SampleRun]], norm='log', figsize=(6, 10)\n",
    "    )\n",
    ")\n",
    "\n",
    "wavelength = iofq.compute(WavelengthBins)\n",
    "display(\n",
    "    results[CleanSummedQ[SampleRun, Numerator]]\n",
    "    .hist(wavelength=wavelength)\n",
    "    .transpose()\n",
    "    .plot(norm='log')\n",
    ")\n",
    "display(results[CleanSummedQ[SampleRun, Denominator]].plot(norm='log'))\n",
    "parts = {str(key): results[key] for key in parts}\n",
    "parts = {\n",
    "    key: val.sum('wavelength') if val.bins is None else val.hist()\n",
    "    for key, val in parts.items()\n",
    "}\n",
    "display(sc.plot(parts, norm='log', scale={'Q': 'log'}))\n",
    "\n",
    "iofqs = {str(key): results[key] for key in iofqs}\n",
    "iofqs = {key: val if val.bins is None else val.hist() for key, val in iofqs.items()}\n",
    "display(sc.plot(iofqs, norm='log', scale={'Q': 'log'}, aspect='equal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63318c7-4d63-4133-97c3-feb56707caba",
   "metadata": {},
   "source": [
    "## Computing Qx/Qy\n",
    "\n",
    "To compute $I(Q_{x}, Q_{y})$ instead of the one-dimensional $I(Q)$,\n",
    "we can simply define some `QxyBins` in our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879702d-424a-462f-8475-6056116d7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[QxyBins] = {\n",
    "    'Qx': sc.linspace(dim='Qx', start=-0.5, stop=0.5, num=101, unit='1/angstrom'),\n",
    "    'Qy': sc.linspace(dim='Qy', start=-0.8, stop=0.8, num=101, unit='1/angstrom'),\n",
    "}\n",
    "\n",
    "iqxqy = make_workflow(pipeline, masks).compute(IofQ[SampleRun])\n",
    "iqxqy.plot(norm='log', aspect='equal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Zoom data reduction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is an example of how ESSsans can be used to reduce data from [Zoom at ISIS](https://www.isis.stfc.ac.uk/Pages/Zoom.aspx).\n",
    "The following description is kept relatively brief, for more context see the rest of the documentation.\n",
    "In particular the [Sans2d](./sans2d.ipynb) notebook may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "There are a few things that are not yet handled:\n",
    "\n",
    "- TOF or wavelength masks\n",
    "- Position corrections from user file (not automatically, have manual sample and detector bank offsets)\n",
    "\n",
    "We begin with relevant imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "from ess import sans\n",
    "from ess import isissans as isis\n",
    "import ess.isissans.data  # noqa: F401\n",
    "from ess.sans.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Create and configure the workflow\n",
    "\n",
    "We begin by creating the Zoom workflow object (this is a [sciline.Pipeline](https://scipp.github.io/sciline/generated/classes/sciline.Pipeline.html) which can be consulted for advanced usage).\n",
    "The Zoom workflow uses Mantid to load files.\n",
    "This tutorial comes with files that do not require Mantid, so we use a slightly modified workflow that does not require Mantid.\n",
    "The workflow is otherwise identical to the full Mantid-based workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = isis.zoom.ZoomTutorialWorkflow()\n",
    "# For real data use:\n",
    "# workflow = isis.zoom.ZoomWorkflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We can insert steps for configuring the workflow.\n",
    "In this case, we would like to use the transmission monitor from the regular background and sample runs since there was no separate transmission run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.insert(isis.io.transmission_from_background_run)\n",
    "workflow.insert(isis.io.transmission_from_sample_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The workflow lacks some input parameters, as well as parameters where we do not want to use the defaults, which we can set now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[NeXusMonitorName[Incident]] = 'monitor3'\n",
    "workflow[NeXusMonitorName[Transmission]] = 'monitor5'\n",
    "\n",
    "workflow[WavelengthBins] = sc.geomspace(\n",
    "    'wavelength', start=1.75, stop=16.5, num=141, unit='angstrom'\n",
    ")\n",
    "\n",
    "workflow[QBins] = sc.geomspace(\n",
    "    dim='Q', start=0.004, stop=0.8, num=141, unit='1/angstrom'\n",
    ")\n",
    "\n",
    "workflow[NonBackgroundWavelengthRange] = sc.array(\n",
    "    dims=['wavelength'], values=[0.7, 17.1], unit='angstrom'\n",
    ")\n",
    "workflow[CorrectForGravity] = True\n",
    "workflow[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.upper_bound\n",
    "workflow[ReturnEvents] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Configuring data to load\n",
    "\n",
    "We have not configured which files we want to load.\n",
    "In this tutorial, we use helpers to fetch the tutorial data which return the filenames of the cached files.\n",
    "In a real use case, you would set these parameters manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[DirectBeamFilename] = isis.data.zoom_tutorial_direct_beam()\n",
    "workflow[isis.CalibrationFilename] = isis.data.zoom_tutorial_calibration()\n",
    "workflow[Filename[SampleRun]] = isis.data.zoom_tutorial_sample_run()\n",
    "workflow[Filename[EmptyBeamRun]] = isis.data.zoom_tutorial_empty_beam_run()\n",
    "workflow[isis.SampleOffset] = sc.vector([0.0, 0.0, 0.11], unit='m')\n",
    "workflow[isis.DetectorBankOffset] = sc.vector([0.0, 0.0, 0.5], unit='m')\n",
    "masks = isis.data.zoom_tutorial_mask_filenames()\n",
    "workflow = sans.with_pixel_mask_filenames(workflow, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The workflow can be visualized as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-right layout works better for this graph\n",
    "workflow.visualize(IntensityQ[SampleRun], graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Use the workflow\n",
    "\n",
    "### Set or compute the beam center\n",
    "\n",
    "The beam center is not set by default.\n",
    "We can either set it to a known value, or compute it from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[BeamCenter] = sans.beam_center_from_center_of_mass(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Compute final result\n",
    "\n",
    "We can now compute $I(Q)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = workflow.compute(IntensityQ[SampleRun])\n",
    "da.plot(norm='log', scale={'Q': 'log'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Compute intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = (\n",
    "    WavelengthMonitor[SampleRun, Incident],\n",
    "    WavelengthMonitor[SampleRun, Transmission],\n",
    ")\n",
    "parts = (\n",
    "    WavelengthScaledQ[SampleRun, Numerator],\n",
    "    WavelengthScaledQ[SampleRun, Denominator],\n",
    ")\n",
    "iofqs = (IntensityQ[SampleRun],)\n",
    "keys = (*monitors, MaskedData[SampleRun], *parts, *iofqs)\n",
    "\n",
    "results = workflow.compute(keys)\n",
    "\n",
    "display(sc.plot({str(key): results[key] for key in monitors}, norm='log'))\n",
    "\n",
    "display(\n",
    "    isis.plot_flat_detector_xy(\n",
    "        results[MaskedData[SampleRun]], norm='log', figsize=(6, 10)\n",
    "    )\n",
    ")\n",
    "\n",
    "wavelength = workflow.compute(WavelengthBins)\n",
    "display(\n",
    "    results[WavelengthScaledQ[SampleRun, Numerator]]\n",
    "    .hist(wavelength=wavelength)\n",
    "    .transpose()\n",
    "    .plot(norm='log')\n",
    ")\n",
    "display(results[WavelengthScaledQ[SampleRun, Denominator]].plot(norm='log'))\n",
    "parts = {str(key): results[key] for key in parts}\n",
    "parts = {\n",
    "    key: val.sum('wavelength') if val.bins is None else val.hist()\n",
    "    for key, val in parts.items()\n",
    "}\n",
    "display(sc.plot(parts, norm='log', scale={'Q': 'log'}))\n",
    "\n",
    "iofqs = {str(key): results[key] for key in iofqs}\n",
    "iofqs = {key: val if val.bins is None else val.hist() for key, val in iofqs.items()}\n",
    "display(sc.plot(iofqs, norm='log', scale={'Q': 'log'}, aspect='equal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Computing Qx/Qy\n",
    "\n",
    "To compute $I(Q_{x}, Q_{y})$ instead of the one-dimensional $I(Q)$, we can compute `IntensityQxy` instead of `IntensityQ`.\n",
    "For this to work, we need to define `QxBins` and `QyBins` in our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[QxBins] = sc.linspace('Qx', start=-0.5, stop=0.5, num=101, unit='1/angstrom')\n",
    "workflow[QyBins] = sc.linspace('Qy', start=-0.8, stop=0.8, num=101, unit='1/angstrom')\n",
    "\n",
    "iqxqy = workflow.compute(IntensityQxy[SampleRun])\n",
    "iqxqy.plot(norm='log', aspect='equal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
